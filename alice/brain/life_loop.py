# -*- coding: utf-8 -*-
"""
Alice's Life Loop — Closed-Loop Error Compensation Engine

Core insight:
  "All human behavior — turning the head, reaching, speaking — is calibration error compensation.
   Behavior is not driven by will, but by cross-modal signal mismatch."

  Life Loop = THE fundamental algorithm of being alive:

    while alive:
        signals = perceive()              # Multi-modal sensory input
        errors  = estimate_errors()       # Cross-modal error estimation
        commands = compensate(errors)      # Generate motor compensation commands
        execute(commands)                  # Body execution
        feedback = re_perceive()           # Action changes perception
        calibrate(feedback)               # Update calibration parameters
        adapt(performance)                # Meta-learning adjusts the system

Circuit analogy:
  Sensor ──→ Error calc ──→ PID ──→ Motor ──→ Environment ──→ Sensor
              ↑                                               │
              └────────── Feedback ←──────────────────────────┘

  This loop IS the coaxial cable signal loop:
  - Signal goes out (motor command)
  - Hits the load (environment)
  - Reflects back (sensory feedback)
  - Reflected energy = physical measurement of error

Biological correspondences:
  Infant = PID gains not tuned → large error → clumsy movements
  Practice = repeated loop runs → meta-learning auto-tunes → error approaches zero
  Expert = error ≈ 0, loop runs extremely fast → illusion of "no thinking needed"
  Aging = sensor degradation → signal quality ↓ → error grows again
  Motion sickness = modal conflict → no motor command can eliminate error → system collapse
"""

from __future__ import annotations

import math
import time
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Dict, List, Optional, Tuple

import numpy as np

from alice.core.signal import ElectricalSignal


# ============================================================================
# Error Type Enumeration
# ============================================================================

class ErrorType(str, Enum):
    """Cross-modal error types"""
    VISUAL_MOTOR = "visual_motor"             # Seen position vs hand position
    AUDITORY_VISUAL = "auditory_visual"       # Heard direction vs seen direction
    AUDITORY_VOCAL = "auditory_vocal"         # Target pitch vs actual pitch
    PROPRIOCEPTIVE = "proprioceptive"         # Target position vs proprioception
    TEMPORAL = "temporal"                     # Temporal drift (cross-modal sync error)
    INTEROCEPTIVE = "interoceptive"           # Body state vs homeostatic target
    SENSORY_PREDICTION = "sensory_prediction" # Expected sensation vs actual sensation


class CompensationAction(str, Enum):
    """Compensation action types"""
    REACH = "reach"               # Reach out
    SACCADE = "saccade"           # Rapid eye movement
    HEAD_TURN = "head_turn"       # Turn head
    VOCALIZE = "vocalize"         # Adjust vocalization
    ADJUST_PUPIL = "adjust_pupil" # Pupil adjustment
    ATTEND = "attend"             # Shift attention
    BREATHE = "breathe"           # Breathing regulation
    NONE = "none"                 # No compensation needed


# ============================================================================
# Error Description
# ============================================================================

@dataclass
class CrossModalError:
    """
    Cross-modal error — the driving force of the life loop

    Every error is a "mismatch that needs to be eliminated".
    Error magnitude determines motor command strength.
    Error = zero → equilibrium → no action needed.
    """
    error_type: ErrorType
    magnitude: float          # Error magnitude 0~1
    direction: np.ndarray     # Error direction vector (meaningful for spatial errors)
    urgency: float            # Urgency 0~1 (affects compensation priority)
    source_modality: str      # Source modality
    target_modality: str      # Target modality
    timestamp: float = field(default_factory=time.time)
    compensation: CompensationAction = CompensationAction.NONE

    @property
    def salience(self) -> float:
        """Salience = error magnitude × urgency"""
        return self.magnitude * self.urgency


@dataclass
class CompensationCommand:
    """
    Compensation command — motor command generated by PID

    The bridge from error to action.
    """
    action: CompensationAction
    target: np.ndarray        # Target state vector
    strength: float           # Command strength 0~1
    source_error: ErrorType   # Error that triggered this command
    priority: float           # Priority (= error.salience)
    timestamp: float = field(default_factory=time.time)


@dataclass
class LoopState:
    """
    Life loop state snapshot

    Each tick produces a LoopState, recording all errors and compensations at that moment.
    """
    tick_id: int
    timestamp: float
    errors: List[CrossModalError]
    commands: List[CompensationCommand]
    total_error: float        # Weighted sum of all errors
    compensation_success: float  # Compensation success rate 0~1
    loop_latency_ms: float    # Loop latency
    consciousness_phi: float  # Current consciousness level
    energy: float             # Current energy


# ============================================================================
# Life Loop Constants
# ============================================================================

# Error threshold — below this value no compensation is triggered (deadband)
ERROR_DEADBAND = 0.05

# Maximum simultaneous compensation commands (attention bottleneck)
MAX_CONCURRENT_COMPENSATIONS = 3

# Error decay (uncompensated errors decay each tick)
ERROR_PERSISTENCE = 0.95

# Compensation gain modulation (affected by anxiety and energy)
ANXIETY_GAIN_PENALTY = 0.4    # Anxiety reduces compensation accuracy by up to 40%
ENERGY_GAIN_PENALTY = 0.3     # Low energy reduces compensation accuracy by up to 30%
CONSCIOUSNESS_GATE = 0.2      # Consciousness below this value → compensation fully stops

# Sensory Prediction Error
PREDICTION_LEARNING_RATE = 0.05  # Prediction model update rate
PREDICTION_DECAY = 0.98          # Prediction memory decay

# Error → Pain conversion (sustained large errors = pain)
# Physics: threshold 0.6 corresponds to |Γ|² = 0.6, i.e., 60% incident energy is reflected.
# Biologically equivalent to "moderate impedance mismatch" — harmful but not catastrophic.
# This matches real neurophysiology: nociceptors start firing *before* tissue damage,
# providing early warning rather than merely reporting existing damage (Woolf & Ma, 2007).
ERROR_TO_PAIN_THRESHOLD = 0.6    # |Γ|² ≥ 0.6 → pain signal generated
ERROR_TO_PAIN_GAIN = 0.1         # Pain generation rate (linear gain)


# ============================================================================
# Life Loop Engine
# ============================================================================

class LifeLoop:
    """
    Life Loop — Alice's closed-loop error compensation engine

    This class connects all modules into a closed loop:
    1. Collect all sensory signals
    2. Compute cross-modal errors
    3. Consciousness ranks errors (attention = error priority)
    4. Generate compensation commands (PID)
    5. Execute compensation (motor organs)
    6. Collect feedback
    7. Update calibration + meta-learning

    It does not OWN any subsystem — it is only the wiring topology.
    Subsystems are owned by AliceBrain; LifeLoop receives references.
    """

    def __init__(self):
        # Loop state
        self._tick_count: int = 0
        self._total_error_history: List[float] = []
        self._compensation_history: List[float] = []
        self._loop_latency_history: List[float] = []

        # Persistent error tracking (unresolved errors accumulate)
        self._persistent_errors: Dict[ErrorType, float] = {
            et: 0.0 for et in ErrorType
        }

        # Sensory prediction model (one expected value per modality)
        self._sensory_predictions: Dict[str, np.ndarray] = {}

        # Last loop's motor commands (used to predict next sensation)
        self._last_commands: List[CompensationCommand] = []

        # Cumulative performance metrics
        self._cumulative_error: float = 0.0
        self._cumulative_compensation: float = 0.0
        self._successful_compensations: int = 0
        self._total_compensations: int = 0

        # History limit
        self._max_history = 300

    # ------------------------------------------------------------------
    # Core loop
    # ------------------------------------------------------------------

    def tick(
        self,
        # --- Sensory input ---
        visual_signal: Optional[ElectricalSignal] = None,
        auditory_signal: Optional[ElectricalSignal] = None,
        proprioception_hand: Optional[ElectricalSignal] = None,
        proprioception_mouth: Optional[ElectricalSignal] = None,
        interoception: Optional[ElectricalSignal] = None,
        # --- Target/expected state ---
        visual_target: Optional[np.ndarray] = None,      # Visual attention target [x, y]
        hand_target: Optional[np.ndarray] = None,         # Hand target position [x, y]
        pitch_target: Optional[float] = None,             # Pitch target Hz
        # --- System state (read from other modules) ---
        hand_position: Optional[np.ndarray] = None,       # Current hand position [x, y]
        current_pitch: float = 0.0,                       # Current pitch Hz
        calibration_drifts: Optional[Dict[str, float]] = None,  # Per-modality drift ms
        calibration_quality: float = 1.0,
        consciousness_phi: float = 0.5,
        arousal: float = 0.5,
        sensory_gate: float = 1.0,
        ram_temperature: float = 0.0,
        energy: float = 1.0,
        pain_level: float = 0.0,
        pupil_aperture: float = 0.5,
        autonomic_balance: float = 0.0,     # -1~+1
    ) -> LoopState:
        """
        One tick of the life loop — single step of closed-loop execution

        Each tick completes:
        1. Estimate all cross-modal errors
        2. Consciousness filtering + priority ranking
        3. Generate compensation commands
        4. Update sensory predictions
        5. Accumulate persistent errors

        Returns:
            LoopState snapshot
        """
        t0 = time.time()
        self._tick_count += 1

        # ============================================================
        # STEP 1: Estimate all cross-modal errors
        # ============================================================
        errors = self._estimate_errors(
            visual_signal=visual_signal,
            auditory_signal=auditory_signal,
            proprioception_hand=proprioception_hand,
            proprioception_mouth=proprioception_mouth,
            interoception=interoception,
            visual_target=visual_target,
            hand_target=hand_target,
            hand_position=hand_position,
            pitch_target=pitch_target,
            current_pitch=current_pitch,
            calibration_drifts=calibration_drifts or {},
            calibration_quality=calibration_quality,
            autonomic_balance=autonomic_balance,
        )

        # ============================================================
        # STEP 2: Sensory gating — sleep/consciousness filtering
        # ============================================================
        gated_errors = self._apply_sensory_gate(errors, sensory_gate)

        # ============================================================
        # STEP 3: Consciousness ranking — attention = error priority
        # ============================================================
        prioritized = self._prioritize_errors(
            gated_errors, consciousness_phi, pain_level,
        )

        # ============================================================
        # STEP 4: Generate compensation commands
        # ============================================================
        commands = self._generate_compensations(
            prioritized,
            ram_temperature=ram_temperature,
            energy=energy,
            consciousness_phi=consciousness_phi,
        )

        # ============================================================
        # STEP 5: Update sensory predictions (forward model)
        # ============================================================
        self._update_predictions(commands)

        # ============================================================
        # STEP 6: Accumulate persistent errors + error → pain
        # ============================================================
        self._update_persistent_errors(prioritized, commands)

        # ============================================================
        # STEP 7: Compute loop metrics
        # ============================================================
        total_error = sum(e.salience for e in prioritized)
        compensation_success = self._compute_compensation_success(
            prioritized, commands,
        )

        loop_ms = (time.time() - t0) * 1000.0

        # Record history
        self._total_error_history.append(total_error)
        self._compensation_history.append(compensation_success)
        self._loop_latency_history.append(loop_ms)
        self._trim_history()

        self._cumulative_error += total_error

        # Build state snapshot
        state = LoopState(
            tick_id=self._tick_count,
            timestamp=time.time(),
            errors=prioritized,
            commands=commands,
            total_error=total_error,
            compensation_success=compensation_success,
            loop_latency_ms=loop_ms,
            consciousness_phi=consciousness_phi,
            energy=energy,
        )

        self._last_commands = commands
        return state

    # ------------------------------------------------------------------
    # STEP 1: Error estimation
    # ------------------------------------------------------------------

    def _estimate_errors(
        self, *,
        visual_signal: Optional[ElectricalSignal],
        auditory_signal: Optional[ElectricalSignal],
        proprioception_hand: Optional[ElectricalSignal],
        proprioception_mouth: Optional[ElectricalSignal],
        interoception: Optional[ElectricalSignal],
        visual_target: Optional[np.ndarray],
        hand_target: Optional[np.ndarray],
        hand_position: Optional[np.ndarray],
        pitch_target: Optional[float],
        current_pitch: float,
        calibration_drifts: Dict[str, float],
        calibration_quality: float,
        autonomic_balance: float,
    ) -> List[CrossModalError]:
        """Estimate all cross-modal errors"""
        errors: List[CrossModalError] = []

        # --- Visual-motor error (hand-eye coordination) ---
        if hand_target is not None and hand_position is not None:
            delta = hand_target - hand_position
            mag = float(np.linalg.norm(delta))
            if mag > ERROR_DEADBAND:
                direction = delta / max(mag, 1e-8)
                errors.append(CrossModalError(
                    error_type=ErrorType.VISUAL_MOTOR,
                    magnitude=min(1.0, mag),
                    direction=direction,
                    urgency=0.8,
                    source_modality="visual",
                    target_modality="proprioception",
                    compensation=CompensationAction.REACH,
                ))

        # --- Auditory-visual error (orienting reflex: head turn) ---
        if (auditory_signal is not None and visual_signal is not None
                and visual_target is not None):
            # Auditory signal frequency features vs visual attention target direction
            # Simplified: use amplitude difference to represent spatial mismatch
            aud_amp = auditory_signal.amplitude
            vis_amp = visual_signal.amplitude
            # Auditory salient but visual not salient → need to turn head
            mismatch = max(0.0, aud_amp - vis_amp) / max(aud_amp, vis_amp, 1e-8)
            if mismatch > ERROR_DEADBAND:
                errors.append(CrossModalError(
                    error_type=ErrorType.AUDITORY_VISUAL,
                    magnitude=min(1.0, mismatch),
                    direction=np.array([1.0, 0.0]),  # Towards auditory source
                    urgency=min(1.0, aud_amp),
                    source_modality="auditory",
                    target_modality="visual",
                    compensation=CompensationAction.HEAD_TURN,
                ))

        # --- Auditory-vocal error (pitch control) ---
        if pitch_target is not None and pitch_target > 0:
            pitch_error = abs(current_pitch - pitch_target) / max(pitch_target, 1.0)
            if pitch_error > ERROR_DEADBAND:
                errors.append(CrossModalError(
                    error_type=ErrorType.AUDITORY_VOCAL,
                    magnitude=min(1.0, pitch_error),
                    direction=np.array([1.0 if current_pitch < pitch_target else -1.0]),
                    urgency=0.6,
                    source_modality="auditory",
                    target_modality="vocal",
                    compensation=CompensationAction.VOCALIZE,
                ))

        # --- Proprioceptive error ---
        if proprioception_hand is not None and hand_target is not None:
            # Proprioceptive amplitude deviation from target → position uncertainty
            prop_error = 1.0 - min(1.0, proprioception_hand.snr / 20.0)
            if prop_error > ERROR_DEADBAND:
                errors.append(CrossModalError(
                    error_type=ErrorType.PROPRIOCEPTIVE,
                    magnitude=prop_error,
                    direction=np.array([0.0, 0.0]),
                    urgency=0.5,
                    source_modality="proprioception",
                    target_modality="proprioception",
                    compensation=CompensationAction.REACH,
                ))

        # --- Temporal drift error ---
        for modality_name, drift_ms in calibration_drifts.items():
            drift_normalized = min(1.0, abs(drift_ms) / 100.0)  # 100ms = max tolerable drift
            if drift_normalized > ERROR_DEADBAND:
                errors.append(CrossModalError(
                    error_type=ErrorType.TEMPORAL,
                    magnitude=drift_normalized,
                    direction=np.array([1.0 if drift_ms > 0 else -1.0]),
                    urgency=0.4 + 0.3 * drift_normalized,
                    source_modality=modality_name,
                    target_modality="temporal",
                    compensation=CompensationAction.ATTEND,
                ))

        # --- Interoceptive error (homeostasis deviation) ---
        # autonomic_balance deviating from 0 (equilibrium) = homeostasis error
        homeostasis_error = abs(autonomic_balance)
        if homeostasis_error > ERROR_DEADBAND:
            errors.append(CrossModalError(
                error_type=ErrorType.INTEROCEPTIVE,
                magnitude=min(1.0, homeostasis_error),
                direction=np.array([-1.0 if autonomic_balance > 0 else 1.0]),
                urgency=0.3 + 0.5 * homeostasis_error,
                source_modality="interoception",
                target_modality="interoception",
                compensation=CompensationAction.BREATHE,
            ))

        # --- Sensory prediction error (expected vs actual) ---
        prediction_errors = self._compute_prediction_errors(
            visual_signal, auditory_signal, proprioception_hand,
        )
        errors.extend(prediction_errors)

        return errors

    # ------------------------------------------------------------------
    # STEP 2: Sensory gating
    # ------------------------------------------------------------------

    def _apply_sensory_gate(
        self,
        errors: List[CrossModalError],
        sensory_gate: float,
    ) -> List[CrossModalError]:
        """
        Sleep/consciousness sensory gating

        gate = 1.0 → all pass through (awake)
        gate = 0.1 → only very strong errors pass (deep sleep)
        """
        gated = []
        for e in errors:
            gated_magnitude = e.magnitude * sensory_gate
            if gated_magnitude > ERROR_DEADBAND:
                gated.append(CrossModalError(
                    error_type=e.error_type,
                    magnitude=gated_magnitude,
                    direction=e.direction,
                    urgency=e.urgency * sensory_gate,
                    source_modality=e.source_modality,
                    target_modality=e.target_modality,
                    timestamp=e.timestamp,
                    compensation=e.compensation,
                ))
        return gated

    # ------------------------------------------------------------------
    # STEP 3: Consciousness ranking
    # ------------------------------------------------------------------

    def _prioritize_errors(
        self,
        errors: List[CrossModalError],
        consciousness_phi: float,
        pain_level: float,
    ) -> List[CrossModalError]:
        """
        Consciousness module's attention = error priority ranking

        - Pain always has highest priority (survival)
        - High consciousness → can process more errors
        - Low consciousness → only process the largest error
        """
        if not errors:
            return []

        # Add cumulative effect of persistent errors
        for e in errors:
            persistent = self._persistent_errors.get(e.error_type, 0.0)
            # Persistent errors increase urgency
            e.urgency = min(1.0, e.urgency + persistent * 0.3)

        # Pain-related errors get priority boost
        if pain_level > 0.3:
            for e in errors:
                if e.error_type == ErrorType.INTEROCEPTIVE:
                    e.urgency = min(1.0, e.urgency + pain_level * 0.5)

        # Sort by salience
        errors.sort(key=lambda e: e.salience, reverse=True)

        # Consciousness bottleneck: low consciousness can only handle few errors
        max_errors = max(1, int(MAX_CONCURRENT_COMPENSATIONS * consciousness_phi / 0.5))
        max_errors = min(max_errors, len(errors))

        return errors[:max_errors]

    # ------------------------------------------------------------------
    # STEP 4: Generate compensation commands
    # ------------------------------------------------------------------

    def _generate_compensations(
        self,
        errors: List[CrossModalError],
        ram_temperature: float,
        energy: float,
        consciousness_phi: float,
    ) -> List[CompensationCommand]:
        """
        Generate compensation commands from errors

        Command strength is affected by:
        - Anxiety (ram_temperature) → reduces accuracy (adds noise)
        - Energy → reduces force
        - Consciousness → below threshold means full stop
        """
        if consciousness_phi < CONSCIOUSNESS_GATE:
            return []  # Unconscious → no voluntary compensation

        commands: List[CompensationCommand] = []

        # Compensation gain modulation
        anxiety_factor = 1.0 - ANXIETY_GAIN_PENALTY * ram_temperature ** 2
        energy_factor = 1.0 - ENERGY_GAIN_PENALTY * (1.0 - energy)
        gain = max(0.1, anxiety_factor * energy_factor)

        for error in errors:
            if error.compensation == CompensationAction.NONE:
                continue

            # Command strength = error magnitude × gain modulation
            strength = error.magnitude * gain

            # Anxiety adds noise (PID control contaminated)
            if ram_temperature > 0.3:
                noise = np.random.normal(0, ram_temperature * 0.1)
                strength = max(0.0, min(1.0, strength + noise))

            commands.append(CompensationCommand(
                action=error.compensation,
                target=error.direction * error.magnitude,
                strength=strength,
                source_error=error.error_type,
                priority=error.salience,
            ))

        # Sort by priority
        commands.sort(key=lambda c: c.priority, reverse=True)

        # Execute at most N compensations simultaneously
        return commands[:MAX_CONCURRENT_COMPENSATIONS]

    # ------------------------------------------------------------------
    # STEP 5: Sensory prediction update
    # ------------------------------------------------------------------

    def _update_predictions(self, commands: List[CompensationCommand]):
        """
        Forward Model — predict the next sensation

        When you reach out, the brain predicts "what tactile sensation should occur when the hand arrives".
        If actual sensation ≠ prediction → sensory prediction error (surprise).

        An infant's forward model is poor → every action is a "surprise".
        Practice → forward model becomes increasingly accurate → actions become "predictable".
        """
        for cmd in commands:
            key = cmd.action.value

            if key not in self._sensory_predictions:
                self._sensory_predictions[key] = cmd.target.copy()
            else:
                # EMA update prediction
                self._sensory_predictions[key] = (
                    (1 - PREDICTION_LEARNING_RATE) * self._sensory_predictions[key]
                    + PREDICTION_LEARNING_RATE * cmd.target
                )

    def _compute_prediction_errors(
        self,
        visual: Optional[ElectricalSignal],
        auditory: Optional[ElectricalSignal],
        proprioception: Optional[ElectricalSignal],
    ) -> List[CrossModalError]:
        """
        Compute sensory prediction errors

        If the forward model predicts visual stimulation but none arrives → prediction error.
        """
        errors: List[CrossModalError] = []

        # Only compute when predictions exist
        for action_key, predicted_target in self._sensory_predictions.items():
            # Prediction decay
            self._sensory_predictions[action_key] = predicted_target * PREDICTION_DECAY

            # Issued REACH command but proprioception doesn't match prediction
            if action_key == "reach" and proprioception is not None:
                pred_magnitude = float(np.linalg.norm(predicted_target))
                if pred_magnitude > ERROR_DEADBAND:
                    # Difference between prediction and actual as prediction error
                    prediction_error = abs(pred_magnitude - proprioception.amplitude)
                    if prediction_error > ERROR_DEADBAND:
                        errors.append(CrossModalError(
                            error_type=ErrorType.SENSORY_PREDICTION,
                            magnitude=min(1.0, prediction_error),
                            direction=predicted_target / max(pred_magnitude, 1e-8),
                            urgency=0.3,
                            source_modality="prediction",
                            target_modality="proprioception",
                            compensation=CompensationAction.ATTEND,
                        ))

        return errors

    # ------------------------------------------------------------------
    # STEP 6: Persistent errors + pain conversion
    # ------------------------------------------------------------------

    def _update_persistent_errors(
        self,
        errors: List[CrossModalError],
        commands: List[CompensationCommand],
    ):
        """
        Update persistent errors

        Compensated errors decrease; uncompensated errors accumulate.
        Persistently accumulated errors eventually → pain.
        """
        # Error types covered by compensation
        compensated_types = {cmd.source_error for cmd in commands}

        for error_type in ErrorType:
            # Decay all persistent errors
            self._persistent_errors[error_type] *= ERROR_PERSISTENCE

            # Accumulate new uncompensated errors
            for e in errors:
                if e.error_type == error_type:
                    if error_type not in compensated_types:
                        # Uncompensated → accumulate
                        self._persistent_errors[error_type] += e.magnitude * 0.1
                    else:
                        # Compensated → decrease
                        self._persistent_errors[error_type] *= 0.7

            # Clamp
            self._persistent_errors[error_type] = min(
                1.0, self._persistent_errors[error_type]
            )

    # ------------------------------------------------------------------
    # Compensation success rate
    # ------------------------------------------------------------------

    def _compute_compensation_success(
        self,
        errors: List[CrossModalError],
        commands: List[CompensationCommand],
    ) -> float:
        """Compute compensation success rate (0~1)"""
        if not errors:
            return 1.0

        total_error = sum(e.magnitude for e in errors)
        total_compensation = sum(c.strength for c in commands)

        if total_error < 1e-8:
            return 1.0

        # Compensation coverage
        coverage = min(1.0, total_compensation / total_error)

        self._total_compensations += len(commands)
        self._successful_compensations += sum(
            1 for c in commands if c.strength > 0.3
        )

        return coverage

    # ------------------------------------------------------------------
    # Public queries
    # ------------------------------------------------------------------

    def get_persistent_errors(self) -> Dict[str, float]:
        """Get all persistent errors"""
        return {et.value: v for et, v in self._persistent_errors.items()}

    def get_total_persistent_error(self) -> float:
        """Get the weighted sum of persistent errors"""
        return sum(self._persistent_errors.values())

    def get_error_to_pain(self) -> float:
        """
        Persistent errors converted to pain

        Long-term unresolvable cross-modal errors → chronic pain
        (This is why sustained noise causes headaches)
        """
        total = self.get_total_persistent_error()
        if total > ERROR_TO_PAIN_THRESHOLD:
            return min(1.0, (total - ERROR_TO_PAIN_THRESHOLD) * ERROR_TO_PAIN_GAIN)
        return 0.0

    def get_prediction_accuracy(self) -> float:
        """Forward model prediction accuracy"""
        if self._total_compensations == 0:
            return 0.5
        return self._successful_compensations / max(1, self._total_compensations)

    def get_stats(self) -> Dict[str, Any]:
        """Full statistics"""
        return {
            "tick_count": self._tick_count,
            "persistent_errors": self.get_persistent_errors(),
            "total_persistent_error": round(self.get_total_persistent_error(), 4),
            "error_to_pain": round(self.get_error_to_pain(), 4),
            "prediction_accuracy": round(self.get_prediction_accuracy(), 4),
            "cumulative_error": round(self._cumulative_error, 4),
            "total_compensations": self._total_compensations,
            "successful_compensations": self._successful_compensations,
            "avg_error": round(
                np.mean(self._total_error_history[-30:]) if self._total_error_history else 0.0,
                4,
            ),
            "avg_compensation": round(
                np.mean(self._compensation_history[-30:]) if self._compensation_history else 0.0,
                4,
            ),
            "avg_latency_ms": round(
                np.mean(self._loop_latency_history[-30:]) if self._loop_latency_history else 0.0,
                4,
            ),
        }

    def get_waveforms(self, last_n: int = 60) -> Dict[str, List[float]]:
        """Waveform data (for dashboard use)"""
        return {
            "total_error": self._total_error_history[-last_n:],
            "compensation": self._compensation_history[-last_n:],
            "loop_latency_ms": self._loop_latency_history[-last_n:],
        }

    def reset(self):
        """Reset"""
        self._tick_count = 0
        self._total_error_history.clear()
        self._compensation_history.clear()
        self._loop_latency_history.clear()
        self._persistent_errors = {et: 0.0 for et in ErrorType}
        self._sensory_predictions.clear()
        self._last_commands.clear()
        self._cumulative_error = 0.0
        self._cumulative_compensation = 0.0
        self._successful_compensations = 0
        self._total_compensations = 0

    def _trim_history(self):
        for hist in (
            self._total_error_history,
            self._compensation_history,
            self._loop_latency_history,
        ):
            if len(hist) > self._max_history:
                del hist[:-self._max_history]
